{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: Setup and Google Drive Mounting\n",
        "\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# 1. Verify GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available and enabled!\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"GPU is not available, running on CPU. Consider enabling GPU in Runtime settings.\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# 2. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"\\nGoogle Drive mounted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqNlbuL4PwTz",
        "outputId": "e53e0fbc-8c1b-42e4-c3c1-1ea8892202c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available and enabled!\n",
            "Mounted at /content/drive\n",
            "\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Define Paths and Unzip Dataset\n",
        "\n",
        "# --- IMPORTANT: Define the paths based on your Google Drive structure ---\n",
        "# This is the folder you created in your Google Drive\n",
        "DRIVE_PROJECT_PATH = '/content/drive/MyDrive/Colab_IntruderDetection/'\n",
        "\n",
        "# Path to the uploaded ZIP file on your Drive\n",
        "ZIP_FILE_PATH = os.path.join(DRIVE_PROJECT_PATH, 'INRIAPerson.zip')\n",
        "\n",
        "# Path where the dataset will be extracted in Colab's temporary storage (for speed)\n",
        "DATASET_EXTRACT_PATH = '/content/INRIAPerson'\n",
        "\n",
        "# Path where the final trained model will be saved on your Google Drive (for persistence)\n",
        "MODEL_SAVE_PATH = os.path.join(DRIVE_PROJECT_PATH, 'person_detector_model.pth')\n",
        "\n",
        "\n",
        "# --- Unzip the dataset ---\n",
        "# We check if the folder already exists to avoid unzipping again on re-running the cell\n",
        "if not os.path.exists(DATASET_EXTRACT_PATH):\n",
        "    print(f\"Extracting dataset from '{ZIP_FILE_PATH}'...\")\n",
        "    # The '-q' flag makes the output quiet\n",
        "    !unzip -q \"{ZIP_FILE_PATH}\" -d \"/content/\"\n",
        "    print(f\"Dataset extracted to '{DATASET_EXTRACT_PATH}'.\")\n",
        "else:\n",
        "    print(f\"Dataset already extracted at '{DATASET_EXTRACT_PATH}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6KXRvDIPwP-",
        "outputId": "1d96eb90-f72b-4bbd-da08-3dc0bcfa35b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset from '/content/drive/MyDrive/Colab_IntruderDetection/INRIAPerson.zip'...\n",
            "Dataset extracted to '/content/INRIAPerson'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Main Training Script\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from PIL import Image\n",
        "\n",
        "# ==============================================================================\n",
        "# 1. DATASET LOADER (CONFIGURED FOR INRIA DATASET STRUCTURE)\n",
        "# ==============================================================================\n",
        "class PersonDetectionDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "\n",
        "        person_dir = os.path.join(root_dir, 'pos')\n",
        "        if os.path.exists(person_dir):\n",
        "            for img_name in os.listdir(person_dir):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.images.append(os.path.join(person_dir, img_name))\n",
        "                    self.labels.append(1)\n",
        "\n",
        "        no_person_dir = os.path.join(root_dir, 'neg')\n",
        "        if os.path.exists(no_person_dir):\n",
        "            for img_name in os.listdir(no_person_dir):\n",
        "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    self.images.append(os.path.join(no_person_dir, img_name))\n",
        "                    self.labels.append(0)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.images[idx]\n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load image {image_path}. Error: {e}\")\n",
        "            return torch.randn(3, 224, 224), torch.tensor(0)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. DEEP LEARNING MODEL (PERSON DETECTOR)\n",
        "# ==============================================================================\n",
        "class PersonDetector(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(PersonDetector, self).__init__()\n",
        "        self.backbone = torchvision.models.resnet18(weights=torchvision.models.ResNet18_Weights.DEFAULT)\n",
        "        for param in list(self.backbone.parameters())[:-10]:\n",
        "            param.requires_grad = False\n",
        "        num_ftrs = self.backbone.fc.in_features\n",
        "        self.backbone.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(num_ftrs, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.backbone(x)\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. MODEL TRAINING FUNCTION\n",
        "# ==============================================================================\n",
        "def train_model(model, train_loader, val_loader, device, num_epochs=15):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"--- Epoch {epoch+1}/{num_epochs} ---\")\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for data, target in train_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * data.size(0)\n",
        "\n",
        "        avg_train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        val_accuracy = 100 * correct / total\n",
        "        print(f'Train Loss: {avg_train_loss:.4f} | Val Accuracy: {val_accuracy:.2f}%')\n",
        "        scheduler.step()\n",
        "\n",
        "    print(\"\\nTraining complete.\")\n",
        "    return model\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. SCRIPT EXECUTION\n",
        "# ==============================================================================\n",
        "# --- Configuration ---\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# --- Data Preparation ---\n",
        "print(\"Preparing dataset...\")\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Use the extracted path for the dataset\n",
        "train_dir = os.path.join(DATASET_EXTRACT_PATH, 'Train')\n",
        "test_dir = os.path.join(DATASET_EXTRACT_PATH, 'Test')\n",
        "\n",
        "train_dataset = PersonDetectionDataset(root_dir=train_dir, transform=transform_train)\n",
        "val_dataset = PersonDetectionDataset(root_dir=test_dir, transform=transform_val)\n",
        "\n",
        "print(f\"Found {len(train_dataset)} training images and {len(val_dataset)} validation images.\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --- Model Training ---\n",
        "print(\"\\nInitializing and training the model...\")\n",
        "model = PersonDetector(num_classes=2).to(device)\n",
        "trained_model = train_model(model, train_loader, val_loader, device, num_epochs=NUM_EPOCHS)\n",
        "\n",
        "# --- Save the Model ---\n",
        "print(f\"Saving trained model to {MODEL_SAVE_PATH}\")\n",
        "torch.save(trained_model.state_dict(), MODEL_SAVE_PATH)\n",
        "print(\"Model saved successfully to your Google Drive.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lxkm_RtPwOK",
        "outputId": "175ea5e3-d585-4b16-865b-69d8bf05a058"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset...\n",
            "Found 1832 training images and 741 validation images.\n",
            "\n",
            "Initializing and training the model...\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 205MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1/15 ---\n",
            "Train Loss: 0.1257 | Val Accuracy: 95.55%\n",
            "--- Epoch 2/15 ---\n",
            "Train Loss: 0.0636 | Val Accuracy: 97.03%\n",
            "--- Epoch 3/15 ---\n",
            "Train Loss: 0.0204 | Val Accuracy: 96.09%\n",
            "--- Epoch 4/15 ---\n",
            "Train Loss: 0.0352 | Val Accuracy: 96.49%\n",
            "--- Epoch 5/15 ---\n",
            "Train Loss: 0.0415 | Val Accuracy: 95.55%\n",
            "--- Epoch 6/15 ---\n",
            "Train Loss: 0.0232 | Val Accuracy: 95.28%\n",
            "--- Epoch 7/15 ---\n",
            "Train Loss: 0.0242 | Val Accuracy: 94.06%\n",
            "--- Epoch 8/15 ---\n",
            "Train Loss: 0.0189 | Val Accuracy: 97.30%\n",
            "--- Epoch 9/15 ---\n",
            "Train Loss: 0.0118 | Val Accuracy: 97.57%\n",
            "--- Epoch 10/15 ---\n",
            "Train Loss: 0.0226 | Val Accuracy: 98.25%\n",
            "--- Epoch 11/15 ---\n",
            "Train Loss: 0.0151 | Val Accuracy: 97.71%\n",
            "--- Epoch 12/15 ---\n",
            "Train Loss: 0.0112 | Val Accuracy: 97.98%\n",
            "--- Epoch 13/15 ---\n",
            "Train Loss: 0.0054 | Val Accuracy: 98.38%\n",
            "--- Epoch 14/15 ---\n",
            "Train Loss: 0.0147 | Val Accuracy: 97.44%\n",
            "--- Epoch 15/15 ---\n",
            "Train Loss: 0.0044 | Val Accuracy: 97.57%\n",
            "\n",
            "Training complete.\n",
            "Saving trained model to /content/drive/MyDrive/Colab_IntruderDetection/person_detector_model.pth\n",
            "Model saved successfully to your Google Drive.\n"
          ]
        }
      ]
    }
  ]
}